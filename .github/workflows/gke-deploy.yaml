name: Build and Deploy to GKE

on:
  push:
    branches:
      - main    # Deploy to dev
      - prod    # Deploy to prod
    # Note: No paths filter - workflow always runs to check for [force build] keyword
    # Change detection happens in detect-changes job

  workflow_dispatch:
    inputs:
      environment:
        description: 'Environment to deploy to'
        required: true
        type: choice
        options:
          - dev
          - prod
      skip_build:
        description: 'Skip image build (use existing images)'
        required: false
        type: boolean
        default: false

env:
  GCP_PROJECT_ID: ${{ vars.GCP_PROJECT_ID }}
  GKE_CLUSTER: ${{ vars.GKE_CLUSTER }}
  GKE_ZONE: ${{ vars.GKE_ZONE }}
  GAR_LOCATION: ${{ vars.GAR_LOCATION }}
  GAR_REPOSITORY: ${{ vars.GAR_REPOSITORY }}

jobs:
  # Detect source commit for image tagging
  # For merge commits (PR merges), use the source commit SHA
  # This allows reusing images built from the source branch
  detect-source-commit:
    name: Detect Source Commit for Images
    runs-on: ubuntu-latest
    outputs:
      source_sha: ${{ steps.detect.outputs.source_sha }}
      is_merge_commit: ${{ steps.detect.outputs.is_merge_commit }}
      skip_build: ${{ steps.detect.outputs.skip_build }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need parent commits

      - name: Detect source commit
        id: detect
        run: |
          CURRENT_SHA="${{ github.sha }}"
          SHORT_SHA=$(echo ${CURRENT_SHA} | cut -c1-7)

          # Check if this is a merge commit by trying to get second parent
          if git rev-parse HEAD^2 &>/dev/null; then
            # This is a merge commit - get the second parent (source branch tip)
            SOURCE_COMMIT=$(git rev-parse HEAD^2)
            SOURCE_SHA=$(echo ${SOURCE_COMMIT} | cut -c1-7)

            echo "is_merge_commit=true" >> $GITHUB_OUTPUT
            echo "source_sha=${SOURCE_SHA}" >> $GITHUB_OUTPUT

            # For prod branch, skip building if it's a merge from main
            # (images should already exist from main branch builds)
            if [[ "${{ github.ref }}" == "refs/heads/prod" ]]; then
              echo "skip_build=true" >> $GITHUB_OUTPUT
              echo "✓ Merge commit detected on prod branch"
              echo "✓ Will use existing images from source commit: ${SOURCE_SHA}"
              echo "✓ Skipping image build to save time and resources"
            else
              echo "skip_build=false" >> $GITHUB_OUTPUT
            fi
          else
            # Not a merge commit - use current commit
            echo "is_merge_commit=false" >> $GITHUB_OUTPUT
            echo "source_sha=${SHORT_SHA}" >> $GITHUB_OUTPUT
            echo "skip_build=false" >> $GITHUB_OUTPUT
            echo "✓ Regular commit detected"
            echo "✓ Will build images with tag: ${SHORT_SHA}"
          fi

          echo ""
          echo "Summary:"
          echo "  Current commit: ${SHORT_SHA}"
          echo "  Source commit for images: $(cat $GITHUB_OUTPUT | grep source_sha | cut -d'=' -f2)"
          echo "  Is merge commit: $(cat $GITHUB_OUTPUT | grep is_merge_commit | cut -d'=' -f2)"
          echo "  Skip build: $(cat $GITHUB_OUTPUT | grep skip_build | cut -d'=' -f2)"

  # Always build all packages on every push (simplified - no change detection)
  detect-changes:
    name: Detect Changed Packages
    runs-on: ubuntu-latest
    outputs:
      agent-api: 'true'
      agent-webapp: 'true'
      burger-api: 'true'
      burger-mcp: 'true'
      burger-webapp: 'true'
      any-changed: 'true'
    steps:
      - name: Always build all packages
        run: |
          echo "✅ Building all packages on every push"
          echo "This workflow now always builds all packages without change detection"

  # Build Docker images
  # Dev: Always build on push to main (uses :latest tag)
  # Prod: Skip build for PR merges (reuse images from source commit)
  build-images:
    name: Build Docker Images
    runs-on: ubuntu-latest
    needs: [detect-source-commit, detect-changes]
    if: |
      needs.detect-source-commit.outputs.skip_build != 'true' &&
      github.event.inputs.skip_build != 'true' &&
      (
        (github.ref == 'refs/heads/main') ||
        (github.ref == 'refs/heads/prod' && needs.detect-changes.outputs.any-changed == 'true')
      )
    permissions:
      contents: read
      id-token: write
    strategy:
      matrix:
        package:
          - agent-api
          - agent-webapp
          - burger-api
          - burger-mcp
          - burger-webapp
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Check if this package should build
        id: should-build
        run: |
          BRANCH="${{ github.ref }}"
          PACKAGE_CHANGED="${{ needs.detect-changes.outputs[matrix.package] }}"

          # Dev (main branch): Always build all packages
          if [[ "${BRANCH}" == "refs/heads/main" ]]; then
            echo "build=true" >> $GITHUB_OUTPUT
            echo "✓ Dev build - building all packages"
          # Prod: Only build if package changed
          elif [[ "${BRANCH}" == "refs/heads/prod" ]] && [[ "${PACKAGE_CHANGED}" == "true" ]]; then
            echo "build=true" >> $GITHUB_OUTPUT
            echo "✓ Prod build - package changed"
          else
            echo "build=false" >> $GITHUB_OUTPUT
            echo "⊘ Skipping build - no changes in prod"
          fi

      - name: Set up Docker Buildx
        if: steps.should-build.outputs.build == 'true'
        uses: docker/setup-buildx-action@v3

      - name: Authenticate to Google Cloud
        if: steps.should-build.outputs.build == 'true'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.WIF_PROVIDER }}
          service_account: ${{ vars.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        if: steps.should-build.outputs.build == 'true'
        uses: google-github-actions/setup-gcloud@v2

      - name: Configure Docker for GAR
        if: steps.should-build.outputs.build == 'true'
        run: |
          gcloud auth configure-docker ${{ env.GAR_LOCATION }}-docker.pkg.dev

      - name: Generate image tags
        if: steps.should-build.outputs.build == 'true'
        id: tags
        run: |
          SHORT_SHA=$(echo ${{ github.sha }} | cut -c1-7)
          IMAGE_BASE="${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.GCP_PROJECT_ID }}/${{ env.GAR_REPOSITORY }}/${{ matrix.package }}"

          # Tag with commit hash (primary identifier)
          echo "commit_tag=${IMAGE_BASE}:${SHORT_SHA}" >> $GITHUB_OUTPUT

          # Tag with branch name
          BRANCH_NAME=$(echo ${GITHUB_REF#refs/heads/} | sed 's/\//-/g')
          echo "branch_tag=${IMAGE_BASE}:${BRANCH_NAME}" >> $GITHUB_OUTPUT

          # Tag with latest if main branch
          if [[ "${{ github.ref }}" == "refs/heads/main" ]]; then
            echo "latest_tag=${IMAGE_BASE}:latest" >> $GITHUB_OUTPUT
          fi

          echo "image_base=${IMAGE_BASE}" >> $GITHUB_OUTPUT
          echo "short_sha=${SHORT_SHA}" >> $GITHUB_OUTPUT

      - name: Build and push Docker image
        if: steps.should-build.outputs.build == 'true'
        uses: docker/build-push-action@v5
        with:
          context: .
          file: packages/${{ matrix.package }}/Dockerfile
          push: true
          tags: |
            ${{ steps.tags.outputs.commit_tag }}
            ${{ steps.tags.outputs.branch_tag }}
            ${{ steps.tags.outputs.latest_tag }}
          platforms: linux/amd64
          no-cache: true

      - name: Output image details
        if: steps.should-build.outputs.build == 'true'
        run: |
          echo "Built and pushed images:"
          echo "- ${{ steps.tags.outputs.commit_tag }}"
          echo "- ${{ steps.tags.outputs.branch_tag }}"
          echo "- ${{ steps.tags.outputs.latest_tag }}"

  # Deploy to environment
  deploy:
    name: Deploy to ${{ matrix.environment }}
    runs-on: ubuntu-latest
    needs: [detect-source-commit, detect-changes, build-images]
    if: always() && (needs.build-images.result == 'success' || needs.build-images.result == 'skipped')
    permissions:
      contents: read
      id-token: write
    strategy:
      matrix:
        include:
          - branch: main
            environment: dev
          - branch: prod
            environment: prod
    environment:
      name: ${{ matrix.environment }}
      url: https://${{ matrix.environment == 'prod' && 'platform-engineering-demo.dev' || 'dev.platform-engineering-demo.dev' }}
    steps:
      - name: Check if deployment should proceed
        id: should-deploy
        run: |
          SHOULD_DEPLOY="false"

          # Check if branch matches environment
          if [[ "${{ github.ref }}" == "refs/heads/${{ matrix.branch }}" ]]; then
            SHOULD_DEPLOY="true"
            echo "✓ Branch ${{ matrix.branch }} matches, deploying to ${{ matrix.environment }}"
          fi

          # Or if manual workflow dispatch specified this environment
          if [[ "${{ github.event.inputs.environment }}" == "${{ matrix.environment }}" ]]; then
            SHOULD_DEPLOY="true"
            echo "✓ Manual deployment to ${{ matrix.environment }} requested"
          fi

          echo "should_deploy=${SHOULD_DEPLOY}" >> $GITHUB_OUTPUT

          if [[ "${SHOULD_DEPLOY}" == "false" ]]; then
            echo "⊘ Skipping deployment: branch ${{ github.ref }} does not match ${{ matrix.environment }}"
            exit 0
          fi

      - name: Checkout code
        if: steps.should-deploy.outputs.should_deploy == 'true'
        uses: actions/checkout@v4

      - name: Authenticate to Google Cloud
        if: steps.should-deploy.outputs.should_deploy == 'true'
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.WIF_PROVIDER }}
          service_account: ${{ vars.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        if: steps.should-deploy.outputs.should_deploy == 'true'
        uses: google-github-actions/setup-gcloud@v2

      - name: Install gke-gcloud-auth-plugin
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          gcloud components install gke-gcloud-auth-plugin

      - name: Get GKE credentials
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          gcloud container clusters get-credentials ${{ env.GKE_CLUSTER }} \
            --zone=${{ env.GKE_ZONE }} \
            --project=${{ env.GCP_PROJECT_ID }}

      - name: Install Kustomize
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | bash
          sudo mv kustomize /usr/local/bin/

      - name: Generate secrets
        if: steps.should-deploy.outputs.should_deploy == 'true'
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          DD_API_KEY: ${{ secrets.DD_API_KEY }}
          POSTGRES_USER: ${{ vars.POSTGRES_USER }}
          POSTGRES_PASSWORD: ${{ secrets.POSTGRES_PASSWORD }}
          POSTGRES_DB: ${{ vars.POSTGRES_DB }}
          JWT_SECRET: ${{ secrets.JWT_SECRET }}
        run: |
          ./k8s/scripts/generate-secrets.sh ${{ matrix.environment }}

      - name: Update image tags in Kustomize
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          # Use source commit SHA for images (handles PR merges)
          SOURCE_SHA="${{ needs.detect-source-commit.outputs.source_sha }}"
          IS_MERGE="${{ needs.detect-source-commit.outputs.is_merge_commit }}"
          IMAGE_BASE="${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.GCP_PROJECT_ID }}/${{ env.GAR_REPOSITORY }}"
          ENV=${{ matrix.environment }}

          cd k8s/overlays/${ENV}

          # Strategy:
          # - Dev: Always use :latest (updated by every push to main)
          # - Prod: Use :source-sha (from PR merge source commit, reusing existing images)
          if [[ "${ENV}" == "dev" ]]; then
            echo "✓ Dev deployment - using :latest tags (always pulls newest build)"

            # Update to use latest tag (which is continuously updated)
            kustomize edit set image \
              gcr.io/${{ env.GCP_PROJECT_ID }}/agent-api=${IMAGE_BASE}/agent-api:latest \
              gcr.io/${{ env.GCP_PROJECT_ID }}/agent-webapp=${IMAGE_BASE}/agent-webapp:latest \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-api=${IMAGE_BASE}/burger-api:latest \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-mcp=${IMAGE_BASE}/burger-mcp:latest \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-webapp=${IMAGE_BASE}/burger-webapp:latest

          elif [[ "${ENV}" == "prod" ]]; then
            if [[ "${IS_MERGE}" == "true" ]]; then
              echo "✓ Prod deployment - PR merge detected"
              echo "✓ Using source commit SHA: ${SOURCE_SHA} (reusing existing images)"
            else
              echo "✓ Prod deployment - direct commit"
              echo "✓ Using commit SHA: ${SOURCE_SHA}"
            fi

            # Update to use source commit hash for immutable deployments
            kustomize edit set image \
              gcr.io/${{ env.GCP_PROJECT_ID }}/agent-api=${IMAGE_BASE}/agent-api:${SOURCE_SHA} \
              gcr.io/${{ env.GCP_PROJECT_ID }}/agent-webapp=${IMAGE_BASE}/agent-webapp:${SOURCE_SHA} \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-api=${IMAGE_BASE}/burger-api:${SOURCE_SHA} \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-mcp=${IMAGE_BASE}/burger-mcp:${SOURCE_SHA} \
              gcr.io/${{ env.GCP_PROJECT_ID }}/burger-webapp=${IMAGE_BASE}/burger-webapp:${SOURCE_SHA}
          fi

      - name: Update Datadog UST version labels
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          # Use source commit SHA for version tracking (matches image tags)
          # For main branch: source_sha = current commit (not a merge)
          # For prod branch: source_sha = PR source commit (reusing images)
          SOURCE_SHA="${{ needs.detect-source-commit.outputs.source_sha }}"
          ENV=${{ matrix.environment }}

          # Always use source commit SHA for VERSION tracking
          # This enables correlating Datadog traces/logs/metrics to exact code version
          echo "✓ Setting VERSION to source commit SHA: ${SOURCE_SHA}"

          # Update version-labels.yaml patch with source commit SHA
          # Replace the default version placeholder with actual commit SHA
          sed -i.bak "s/version: ${ENV}-local/version: ${SOURCE_SHA}/g" \
            k8s/overlays/${ENV}/patches/version-labels.yaml

          # Also update VERSION environment variable value
          # Quote the value to ensure it's treated as a string, not a number
          sed -i.bak "s/value: ${ENV}-local/value: \"${SOURCE_SHA}\"/g" \
            k8s/overlays/${ENV}/patches/version-labels.yaml

          echo "Updated version labels:"
          grep -E "version:|value:" k8s/overlays/${ENV}/patches/version-labels.yaml | head -10

      - name: Deploy with Canary Strategy
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          ENV=${{ matrix.environment }}
          NAMESPACE="mcp-agent-${ENV}"
          # Use source commit SHA (handles PR merges correctly)
          SOURCE_SHA="${{ needs.detect-source-commit.outputs.source_sha }}"

          echo "Deploying to ${ENV} environment (namespace: ${NAMESPACE})"
          echo "Using image tag: ${SOURCE_SHA}"

          # Apply base infrastructure (ConfigMaps, Services, etc.)
          kubectl apply -k k8s/overlays/${ENV}

          # For production, use canary deployment strategy (parallel for all services)
          if [[ "${ENV}" == "prod" ]]; then
            echo "Using parallel canary deployment strategy for production"
            echo "This deploys all canaries at once for faster deployment"

            # Get list of deployments (excluding existing canaries)
            DEPLOYMENTS=$(kubectl get deployments -n ${NAMESPACE} -o name | grep -v canary || true)

            if [[ -z "${DEPLOYMENTS}" ]]; then
              echo "No deployments found to deploy canaries for"
              exit 1
            fi

            echo "Found deployments:"
            echo "${DEPLOYMENTS}"
            echo ""

            # Phase 1: Create all canary deployments in parallel
            echo "=== Phase 1: Creating all canary deployments ==="
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              echo "Creating canary for ${DEPLOY_NAME}..."

              # Clean up any existing canary deployment first
              kubectl delete deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} --ignore-not-found=true

              # Create canary deployment using precise sed replacement
              # Only replace in metadata.name, metadata.labels, spec.selector, and spec.template.metadata.labels
              # Do NOT replace in image URLs or other fields
              kubectl get deployment ${DEPLOY_NAME} -n ${NAMESPACE} -o yaml | \
                sed "/metadata:/,/^[^ ]/ s/name: ${DEPLOY_NAME}$/name: ${DEPLOY_NAME}-canary/" | \
                sed "/labels:/,/^[^ ][^ ]/ s/service: ${DEPLOY_NAME}$/service: ${DEPLOY_NAME}-canary/" | \
                sed "/matchLabels:/,/^[^ ][^ ]/ s/service: ${DEPLOY_NAME}$/service: ${DEPLOY_NAME}-canary/" | \
                sed "s|ad.datadoghq.com/${DEPLOY_NAME}|ad.datadoghq.com/${DEPLOY_NAME}-canary|g" | \
                kubectl apply -f -

              # Scale canary to 1 replica
              kubectl scale deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} --replicas=1 &
            done

            # Wait for all background scale operations
            wait

            echo ""
            echo "=== Phase 2: Waiting for all canaries to become ready ==="
            # Wait for all canaries to be ready (in parallel)
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              echo "Waiting for ${DEPLOY_NAME}-canary to be ready..."
              kubectl rollout status deployment/${DEPLOY_NAME}-canary -n ${NAMESPACE} --timeout=5m &
            done

            # Wait for all rollout status checks
            if ! wait; then
              echo ""
              echo "❌ One or more canary deployments failed to become ready"
              echo "Rolling back all canaries..."
              for DEPLOYMENT in ${DEPLOYMENTS}; do
                DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
                kubectl delete deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} --ignore-not-found=true
              done
              exit 1
            fi

            echo ""
            echo "✅ All canaries are ready"
            echo ""

            # Phase 3: Health check - monitor for 30 seconds
            echo "=== Phase 3: Monitoring canary health for 30 seconds ==="
            sleep 30

            # Check if all canary pods are still healthy
            echo "Checking canary health..."
            FAILED_CANARIES=""
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              CANARY_READY=$(kubectl get deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} -o jsonpath='{.status.readyReplicas}')

              if [[ "${CANARY_READY}" -lt 1 ]]; then
                echo "❌ ${DEPLOY_NAME}-canary failed health check (ready replicas: ${CANARY_READY})"
                FAILED_CANARIES="${FAILED_CANARIES} ${DEPLOY_NAME}"
              else
                echo "✅ ${DEPLOY_NAME}-canary is healthy (ready replicas: ${CANARY_READY})"
              fi
            done

            if [[ -n "${FAILED_CANARIES}" ]]; then
              echo ""
              echo "❌ Canary health check failed for:${FAILED_CANARIES}"
              echo "Rolling back all canaries..."
              for DEPLOYMENT in ${DEPLOYMENTS}; do
                DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
                kubectl delete deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} --ignore-not-found=true
              done
              exit 1
            fi

            echo ""
            echo "✅ All canaries passed health check"
            echo ""

            # Phase 4: Update all main deployments in parallel
            echo "=== Phase 4: Rolling out new version to all main deployments ==="
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              echo "Updating ${DEPLOY_NAME} to version ${SOURCE_SHA}..."

              kubectl set image deployment/${DEPLOY_NAME} -n ${NAMESPACE} \
                ${DEPLOY_NAME}=${GAR_LOCATION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPOSITORY}/${DEPLOY_NAME}:${SOURCE_SHA} &
            done

            # Wait for all image updates
            wait

            echo ""
            echo "Waiting for all main deployments to roll out..."

            # Wait for all main deployments to complete rollout (in parallel)
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              echo "Waiting for ${DEPLOY_NAME} rollout..."
              kubectl rollout status deployment/${DEPLOY_NAME} -n ${NAMESPACE} --timeout=5m &
            done

            # Wait for all rollouts to complete
            if ! wait; then
              echo ""
              echo "❌ One or more main deployments failed to roll out"
              echo "Canaries are still running for potential rollback"
              exit 1
            fi

            echo ""
            echo "✅ All main deployments rolled out successfully"
            echo ""

            # Phase 5: Clean up all canary deployments
            echo "=== Phase 5: Cleaning up canary deployments ==="
            for DEPLOYMENT in ${DEPLOYMENTS}; do
              DEPLOY_NAME=$(echo ${DEPLOYMENT} | cut -d'/' -f2)
              echo "Deleting ${DEPLOY_NAME}-canary..."
              kubectl delete deployment ${DEPLOY_NAME}-canary -n ${NAMESPACE} --ignore-not-found=true &
            done

            # Wait for all deletions
            wait

            echo ""
            echo "✅ Parallel canary deployment completed successfully for all services"
          else
            # For dev, use standard rolling update
            echo "Using standard rolling update for dev environment"
            kubectl rollout restart deployment -n ${NAMESPACE}
          fi

      - name: Verify deployment
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          ENV=${{ matrix.environment }}
          NAMESPACE="mcp-agent-${ENV}"
          # Use source commit SHA for verification (matches deployed images)
          SOURCE_SHA="${{ needs.detect-source-commit.outputs.source_sha }}"
          EXPECTED_VERSION="${SOURCE_SHA}"

          echo "Verifying deployments in ${NAMESPACE} for version: ${EXPECTED_VERSION}..."
          kubectl get deployments -n ${NAMESPACE}
          kubectl get pods -n ${NAMESPACE} -L tags.datadoghq.com/version

          echo ""
          echo "Waiting for rollout of version ${EXPECTED_VERSION} to complete (timeout: 600s)..."

          # Use kubectl rollout status with label selector to check only deployments with the new version
          if ! kubectl rollout status deployment -n ${NAMESPACE} \
            -l tags.datadoghq.com/version=${EXPECTED_VERSION} \
            --timeout=600s; then

            echo ""
            echo "❌ Deployment rollout failed for version ${EXPECTED_VERSION}"
            echo ""
            echo "Checking deployment status:"
            kubectl get deployments -n ${NAMESPACE} -o wide
            echo ""
            echo "Checking pod status:"
            kubectl get pods -n ${NAMESPACE} -o wide -L tags.datadoghq.com/version
            echo ""
            echo "Checking for failed pods:"
            FAILED_PODS=$(kubectl get pods -n ${NAMESPACE} --field-selector=status.phase!=Running,status.phase!=Succeeded -o jsonpath='{.items[*].metadata.name}')

            if [[ -n "${FAILED_PODS}" ]]; then
              echo "Failed pods: ${FAILED_PODS}"
              for pod in ${FAILED_PODS}; do
                echo ""
                echo "==== Logs for ${pod} ===="
                kubectl logs -n ${NAMESPACE} ${pod} --tail=50 || echo "Could not fetch logs for ${pod}"
                echo ""
                echo "==== Events for ${pod} ===="
                kubectl describe pod -n ${NAMESPACE} ${pod} | grep -A 20 "Events:"
              done
            fi

            exit 1
          fi

          echo ""
          echo "✅ All deployments with version ${EXPECTED_VERSION} rolled out successfully"
          echo ""
          echo "Final status - pods with version ${EXPECTED_VERSION}:"
          kubectl get pods -n ${NAMESPACE} -l tags.datadoghq.com/version=${EXPECTED_VERSION} -o wide

      - name: Run smoke tests
        if: steps.should-deploy.outputs.should_deploy == 'true'
        run: |
          ENV=${{ matrix.environment }}

          if [[ "${ENV}" == "prod" ]]; then
            AGENT_URL="https://platform-engineering-demo.dev"
            BURGER_API_URL="https://burger-api.platform-engineering-demo.dev"
          else
            AGENT_URL="https://dev.platform-engineering-demo.dev"
            BURGER_API_URL="https://burger-api-dev.platform-engineering-demo.dev"
          fi

          echo "Running smoke tests..."

          # Test burger-api health
          curl -f ${BURGER_API_URL}/api/burgers | jq '.[] | .name' | head -3

          echo "Smoke tests passed!"

      - name: Notify deployment status
        if: always()
        run: |
          if [[ "${{ job.status }}" == "success" ]]; then
            echo "✅ Deployment to ${{ matrix.environment }} successful!"
          else
            echo "❌ Deployment to ${{ matrix.environment }} failed!"
          fi

  # Cleanup old images
  cleanup:
    name: Cleanup Old Images
    runs-on: ubuntu-latest
    needs: deploy
    if: success()
    permissions:
      contents: read
      id-token: write
    steps:
      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ vars.WIF_PROVIDER }}
          service_account: ${{ vars.WIF_SERVICE_ACCOUNT }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Clean up old images (keep last 10)
        run: |
          PACKAGES="agent-api agent-webapp burger-api burger-mcp burger-webapp"

          for PACKAGE in ${PACKAGES}; do
            echo "Cleaning up old images for ${PACKAGE}..."

            # Get all image digests sorted by creation time
            gcloud artifacts docker images list \
              ${GAR_LOCATION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPOSITORY}/${PACKAGE} \
              --format="get(digest)" \
              --sort-by="~createTime" \
              --limit=1000 | tail -n +11 | while read DIGEST; do

              if [[ ! -z "${DIGEST}" ]]; then
                echo "Deleting ${PACKAGE}@${DIGEST}"
                gcloud artifacts docker images delete \
                  ${GAR_LOCATION}-docker.pkg.dev/${GCP_PROJECT_ID}/${GAR_REPOSITORY}/${PACKAGE}@${DIGEST} \
                  --quiet || true
              fi
            done
          done
